{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task C2:\n",
    "Implementing 2-layered Convolutional Model trained with RadioML Dataset to predict LouisaML_Reduced Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as scio\n",
    "import h5py\n",
    "from keras.utils import np_utils\n",
    "import keras.models as models\n",
    "from keras.layers.core import Reshape,Dense,Dropout,Activation,Flatten\n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.regularizers import *\n",
    "from keras.optimizers import *\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import Callback\n",
    "from sklearn import metrics\n",
    "import matplotlib\n",
    "matplotlib.use('Qt5Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import random, keras\n",
    "import time\n",
    "import _pickle as cPickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing\n",
    "Load Dataset, inspect keys, load dataset as array of miostruct objects and inspect its shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__globals__', '__version__', '__header__', 'dataset'])\n",
      "(8, 20)\n"
     ]
    }
   ],
   "source": [
    "S=scio.loadmat('LouisaML_Reduced.mat');\n",
    "print(S.keys()) \n",
    "data=S['dataset'] \n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract modulation types(label), sigvalue (A) and snr information (snr) from data, i.e. get rid of elements that we do not need and flatten the indexing. Make sure the dataset is not sparse (filled with zeros) or overlaps (double 1s in label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label[0][5][514] [1 0 0 0]\n",
      "label.shape (8, 20)\n",
      "label_after_unravel [0 1 0 0]\n",
      "lbl [[1 0 0 0]\n",
      " [1 0 0 0]\n",
      " [1 0 0 0]\n",
      " ..., \n",
      " [0 0 0 1]\n",
      " [0 0 0 1]\n",
      " [0 0 0 1]] 160000\n",
      "lbl.shape (160000, 4)\n",
      "lbl[5514] [1 0 0 0]\n",
      "A[7][18].shape (1000, 2, 128)\n",
      "(20,)\n",
      "label [[1 0 0 0]\n",
      " [1 0 0 0]\n",
      " [1 0 0 0]\n",
      " ..., \n",
      " [0 0 0 1]\n",
      " [0 0 0 1]\n",
      " [0 0 0 1]]\n",
      "(4,)\n",
      "A.shape: (160000, 2, 128)\n",
      "snr [[ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " ..., \n",
      " [19]\n",
      " [19]\n",
      " [19]] 160000\n",
      "snr.shape and type (160000, 1) <class 'numpy.ndarray'>\n",
      "snr[15984] [15]\n"
     ]
    }
   ],
   "source": [
    "label=data[:,:]['label']\n",
    "#label_before_unravel has 3 level indexes\n",
    "print('label[0][5][514]',label[0][5][514])\n",
    "print('label.shape',label.shape)\n",
    "#label.ravel() returns contiguous flattened array\n",
    "label=label.ravel()\n",
    "print('label_after_unravel',label[20][999])\n",
    "lbl=np.vstack(label)\n",
    "print('lbl',lbl, len(lbl))\n",
    "print('lbl.shape',lbl.shape)\n",
    "print('lbl[5514]',lbl[5514])\n",
    "\n",
    "A=data[:,:]['A']\n",
    "print('A[7][18].shape', A[7][18].shape)\n",
    "print(A[7].shape)\n",
    "A=A.ravel()\n",
    "A=np.vstack(A)\n",
    "print('label',lbl)\n",
    "print(label[7][2].shape)\n",
    "print(\"A.shape:\",A.shape)\n",
    "\n",
    "snr=data[:,:]['snr']\n",
    "snr=snr.ravel()\n",
    "snr=np.vstack(snr)\n",
    "print('snr',snr, len(snr))\n",
    "print('snr.shape and type',snr.shape, type(snr))\n",
    "print('snr[15984]',snr[15984])\n",
    "snr=snr.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating labels in dictionary format, i.e. keys in the form of tuple (modulation type, SNR type). Total number of keys should be No. of modulation types * No. of SNR types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([('64QAM', 3), ('64QAM', 13), ('BPSK', 18), ('16QAM', 3), ('BPSK', 8), ('QPSK', 15), ('QPSK', 0), ('16QAM', 10), ('64QAM', 7), ('BPSK', 12), ('16QAM', 17), ('64QAM', 16), ('16QAM', 6), ('BPSK', 3), ('16QAM', 16), ('QPSK', 7), ('QPSK', 17), ('64QAM', 2), ('64QAM', 4), ('16QAM', 2), ('BPSK', 7), ('QPSK', 3), ('64QAM', 15), ('16QAM', 13), ('16QAM', 19), ('64QAM', 6), ('QPSK', 13), ('BPSK', 11), ('64QAM', 14), ('64QAM', 12), ('16QAM', 9), ('BPSK', 2), ('QPSK', 14), ('QPSK', 6), ('QPSK', 16), ('64QAM', 9), ('64QAM', 19), ('BPSK', 16), ('16QAM', 5), ('BPSK', 6), ('QPSK', 2), ('16QAM', 12), ('64QAM', 10), ('64QAM', 1), ('16QAM', 1), ('BPSK', 10), ('64QAM', 18), ('QPSK', 11), ('16QAM', 8), ('BPSK', 1), ('16QAM', 18), ('64QAM', 5), ('QPSK', 19), ('BPSK', 14), ('QPSK', 12), ('16QAM', 15), ('16QAM', 4), ('BPSK', 5), ('QPSK', 5), ('QPSK', 4), ('BPSK', 15), ('64QAM', 0), ('BPSK', 19), ('16QAM', 0), ('BPSK', 9), ('QPSK', 1), ('16QAM', 11), ('BPSK', 0), ('QPSK', 8), ('64QAM', 11), ('QPSK', 18), ('QPSK', 9), ('BPSK', 13), ('64QAM', 17), ('16QAM', 7), ('BPSK', 4), ('BPSK', 17), ('64QAM', 8), ('QPSK', 10), ('16QAM', 14)]) 80\n"
     ]
    }
   ],
   "source": [
    "n=['BPSK','QPSK','16QAM','64QAM']\n",
    "k=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19]\n",
    "keys = [(n,k) for k in [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19] for n in ['BPSK','QPSK','16QAM','64QAM']]\n",
    "\n",
    "labelDictionary={}\n",
    "for i in range(len(keys)):\n",
    "    for j in range(1000):\n",
    "        labelDictionary[keys[i]]=A[j]\n",
    "print(labelDictionary.keys(), len(labelDictionary.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Split for Training, Test, Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A.shape[0]: 160000\n",
      "A_validation : [[  4.76589601e-03  -8.39680207e-03  -9.69669676e-04  -1.30235452e-02\n",
      "   -1.42604281e-02   3.30993651e-03   2.06726595e-03  -4.64013275e-03\n",
      "    2.73783868e-03  -3.22163011e-03  -4.93991292e-03  -5.30492112e-03\n",
      "   -3.88759067e-03  -1.35701533e-03  -3.35151521e-03   4.50426370e-03\n",
      "    1.69548192e-03  -2.01290870e-03  -3.23605546e-03   9.53620540e-05\n",
      "   -1.02452811e-05   2.22020748e-03  -5.63387386e-04   5.51849686e-03\n",
      "    1.67515307e-03  -2.02031302e-03  -3.67312348e-03  -5.07519912e-03\n",
      "    1.34373465e-03  -4.66858843e-03   7.89879036e-03  -2.95486122e-03\n",
      "   -1.97536626e-03  -3.73153936e-03  -1.76904549e-02  -1.11928855e-02\n",
      "    5.42259525e-03  -4.79759887e-03  -6.71123337e-03   1.34118527e-02\n",
      "    1.09320711e-02   2.65144179e-03  -4.69330529e-03  -3.19556194e-03\n",
      "   -8.00064210e-03  -4.20395124e-03  -7.22356726e-03   9.47140311e-03\n",
      "    2.06095171e-04  -2.27902868e-04   1.99382043e-03  -5.73761578e-03\n",
      "    6.01205887e-03  -8.51660023e-04   1.82183350e-03   3.12323689e-03\n",
      "    7.59229369e-04   6.50205188e-03   3.98965696e-03   1.23402987e-03\n",
      "    1.34007686e-02   3.12180416e-03   3.43118938e-03   5.17477251e-03\n",
      "    3.65420958e-03  -5.91814959e-03  -9.72248205e-03   7.73818195e-03\n",
      "    4.02091884e-03   3.31685378e-03   4.16732730e-03  -8.48329158e-03\n",
      "   -1.43532808e-04   7.35760901e-03   5.63266300e-03   7.90575812e-04\n",
      "    3.18557088e-03  -8.75445247e-04   2.86711619e-04   1.38913562e-02\n",
      "    3.21011030e-03   5.35365624e-03  -4.20714891e-03   3.86704789e-03\n",
      "    6.79765201e-03  -5.10059377e-03  -4.69038767e-03  -3.46678172e-03\n",
      "   -4.57061863e-03  -6.88672185e-03  -1.34837084e-02  -1.21710951e-02\n",
      "    3.30057205e-03   2.87344941e-03  -6.15747169e-03  -3.43058074e-03\n",
      "    9.14135339e-03   4.72165294e-03  -3.24624875e-03   5.61296535e-03\n",
      "    1.36324658e-03  -7.70496726e-03  -6.21716252e-03  -5.55895877e-03\n",
      "   -1.87902491e-03   1.71625320e-03   2.49629700e-03  -1.15134986e-03\n",
      "    6.74784726e-03   7.37778010e-03   2.26772248e-02   6.74752889e-03\n",
      "    5.04970808e-03   5.90673681e-03   6.64249822e-03   5.12350211e-03\n",
      "   -1.46342924e-02   2.02100289e-03  -4.58368988e-03  -2.15254464e-03\n",
      "   -1.50722011e-02  -1.41993736e-02   2.44945748e-03   5.19727376e-03\n",
      "   -3.16543628e-03  -4.82256843e-03  -4.47000760e-03  -2.65917310e-03]\n",
      " [ -3.57533404e-03  -5.88726304e-03  -4.57527080e-03  -3.65001369e-03\n",
      "   -1.91840206e-03  -2.89371525e-05  -1.06571065e-03   3.70367822e-03\n",
      "    8.18833459e-03  -3.24517420e-03   4.03166456e-03   6.65512006e-03\n",
      "    6.99949690e-04   7.37689734e-04   9.60649560e-04  -1.87994449e-03\n",
      "    5.82837824e-04   2.86100422e-03   4.31901458e-03   7.36808953e-03\n",
      "   -4.65100797e-03   7.28015074e-03   6.45549433e-03  -3.54963946e-03\n",
      "    5.51369121e-03   9.99548670e-04  -1.19909773e-03   3.71267318e-03\n",
      "   -8.15622345e-03  -3.52195067e-03   7.38705432e-03  -9.26646288e-03\n",
      "    3.61687210e-03   4.82837128e-03  -3.86069237e-03  -9.37402852e-03\n",
      "    1.17060421e-02   9.53780529e-03  -5.93302069e-03   5.88421516e-03\n",
      "   -7.21935219e-04  -7.67161805e-04   3.49646122e-04   1.72078556e-03\n",
      "   -2.52744445e-03   7.17828235e-03  -2.14168194e-03   3.14614129e-04\n",
      "    5.92323254e-03  -1.53542207e-03   6.39931731e-04   1.15376582e-03\n",
      "   -2.42305955e-03   2.34118630e-03  -6.81451354e-04   5.20455515e-04\n",
      "   -5.85683977e-03  -3.24603455e-03   3.82378914e-03  -5.88893218e-03\n",
      "   -3.58732387e-03  -9.62062207e-03  -6.83037292e-03  -9.72428617e-03\n",
      "    6.68160192e-03   8.78521555e-03  -2.10963396e-04  -3.99166190e-03\n",
      "   -2.88525560e-03  -4.30228899e-03   1.88145540e-04  -4.97324440e-03\n",
      "   -7.58500202e-03  -5.18530510e-03   1.04802267e-03   8.87239733e-03\n",
      "    3.39437370e-03  -1.60039378e-02  -9.14519098e-03  -3.62202451e-03\n",
      "   -4.39079740e-03   7.39436441e-05  -1.25914729e-02   1.05320012e-02\n",
      "   -1.34641420e-03   6.99092246e-03   1.41283790e-03   1.19854028e-02\n",
      "    1.75817156e-02   4.28777153e-03   5.54703152e-03  -1.42629195e-03\n",
      "    1.20903328e-04   1.19237806e-03   3.34065322e-03  -4.65388719e-03\n",
      "   -6.89759483e-03  -9.52234454e-03   5.80749131e-03   4.29274870e-03\n",
      "   -4.28831390e-03   4.36484589e-03   6.26847661e-03  -7.91304951e-03\n",
      "   -6.66092621e-03   3.39185785e-03   5.23093644e-03  -1.23205866e-02\n",
      "   -9.14520338e-03  -3.70505174e-03  -4.71375087e-03   1.37359606e-04\n",
      "    2.38594249e-03  -2.25520045e-03   4.81146547e-03  -2.35209257e-03\n",
      "    6.19867364e-04   5.62475781e-03  -1.61205596e-03   9.30042071e-03\n",
      "   -4.91606090e-03   3.39154627e-03  -2.54190026e-03   1.06651034e-03\n",
      "    6.87292967e-03   1.28502055e-02   2.52497010e-04  -9.44680382e-03]]\n",
      "Y_validation : [1 0 0 0]\n",
      "A_validation : [[  4.76589601e-03  -8.39680207e-03  -9.69669676e-04  -1.30235452e-02\n",
      "   -1.42604281e-02   3.30993651e-03   2.06726595e-03  -4.64013275e-03\n",
      "    2.73783868e-03  -3.22163011e-03  -4.93991292e-03  -5.30492112e-03\n",
      "   -3.88759067e-03  -1.35701533e-03  -3.35151521e-03   4.50426370e-03\n",
      "    1.69548192e-03  -2.01290870e-03  -3.23605546e-03   9.53620540e-05\n",
      "   -1.02452811e-05   2.22020748e-03  -5.63387386e-04   5.51849686e-03\n",
      "    1.67515307e-03  -2.02031302e-03  -3.67312348e-03  -5.07519912e-03\n",
      "    1.34373465e-03  -4.66858843e-03   7.89879036e-03  -2.95486122e-03\n",
      "   -1.97536626e-03  -3.73153936e-03  -1.76904549e-02  -1.11928855e-02\n",
      "    5.42259525e-03  -4.79759887e-03  -6.71123337e-03   1.34118527e-02\n",
      "    1.09320711e-02   2.65144179e-03  -4.69330529e-03  -3.19556194e-03\n",
      "   -8.00064210e-03  -4.20395124e-03  -7.22356726e-03   9.47140311e-03\n",
      "    2.06095171e-04  -2.27902868e-04   1.99382043e-03  -5.73761578e-03\n",
      "    6.01205887e-03  -8.51660023e-04   1.82183350e-03   3.12323689e-03\n",
      "    7.59229369e-04   6.50205188e-03   3.98965696e-03   1.23402987e-03\n",
      "    1.34007686e-02   3.12180416e-03   3.43118938e-03   5.17477251e-03\n",
      "    3.65420958e-03  -5.91814959e-03  -9.72248205e-03   7.73818195e-03\n",
      "    4.02091884e-03   3.31685378e-03   4.16732730e-03  -8.48329158e-03\n",
      "   -1.43532808e-04   7.35760901e-03   5.63266300e-03   7.90575812e-04\n",
      "    3.18557088e-03  -8.75445247e-04   2.86711619e-04   1.38913562e-02\n",
      "    3.21011030e-03   5.35365624e-03  -4.20714891e-03   3.86704789e-03\n",
      "    6.79765201e-03  -5.10059377e-03  -4.69038767e-03  -3.46678172e-03\n",
      "   -4.57061863e-03  -6.88672185e-03  -1.34837084e-02  -1.21710951e-02\n",
      "    3.30057205e-03   2.87344941e-03  -6.15747169e-03  -3.43058074e-03\n",
      "    9.14135339e-03   4.72165294e-03  -3.24624875e-03   5.61296535e-03\n",
      "    1.36324658e-03  -7.70496726e-03  -6.21716252e-03  -5.55895877e-03\n",
      "   -1.87902491e-03   1.71625320e-03   2.49629700e-03  -1.15134986e-03\n",
      "    6.74784726e-03   7.37778010e-03   2.26772248e-02   6.74752889e-03\n",
      "    5.04970808e-03   5.90673681e-03   6.64249822e-03   5.12350211e-03\n",
      "   -1.46342924e-02   2.02100289e-03  -4.58368988e-03  -2.15254464e-03\n",
      "   -1.50722011e-02  -1.41993736e-02   2.44945748e-03   5.19727376e-03\n",
      "   -3.16543628e-03  -4.82256843e-03  -4.47000760e-03  -2.65917310e-03]\n",
      " [ -3.57533404e-03  -5.88726304e-03  -4.57527080e-03  -3.65001369e-03\n",
      "   -1.91840206e-03  -2.89371525e-05  -1.06571065e-03   3.70367822e-03\n",
      "    8.18833459e-03  -3.24517420e-03   4.03166456e-03   6.65512006e-03\n",
      "    6.99949690e-04   7.37689734e-04   9.60649560e-04  -1.87994449e-03\n",
      "    5.82837824e-04   2.86100422e-03   4.31901458e-03   7.36808953e-03\n",
      "   -4.65100797e-03   7.28015074e-03   6.45549433e-03  -3.54963946e-03\n",
      "    5.51369121e-03   9.99548670e-04  -1.19909773e-03   3.71267318e-03\n",
      "   -8.15622345e-03  -3.52195067e-03   7.38705432e-03  -9.26646288e-03\n",
      "    3.61687210e-03   4.82837128e-03  -3.86069237e-03  -9.37402852e-03\n",
      "    1.17060421e-02   9.53780529e-03  -5.93302069e-03   5.88421516e-03\n",
      "   -7.21935219e-04  -7.67161805e-04   3.49646122e-04   1.72078556e-03\n",
      "   -2.52744445e-03   7.17828235e-03  -2.14168194e-03   3.14614129e-04\n",
      "    5.92323254e-03  -1.53542207e-03   6.39931731e-04   1.15376582e-03\n",
      "   -2.42305955e-03   2.34118630e-03  -6.81451354e-04   5.20455515e-04\n",
      "   -5.85683977e-03  -3.24603455e-03   3.82378914e-03  -5.88893218e-03\n",
      "   -3.58732387e-03  -9.62062207e-03  -6.83037292e-03  -9.72428617e-03\n",
      "    6.68160192e-03   8.78521555e-03  -2.10963396e-04  -3.99166190e-03\n",
      "   -2.88525560e-03  -4.30228899e-03   1.88145540e-04  -4.97324440e-03\n",
      "   -7.58500202e-03  -5.18530510e-03   1.04802267e-03   8.87239733e-03\n",
      "    3.39437370e-03  -1.60039378e-02  -9.14519098e-03  -3.62202451e-03\n",
      "   -4.39079740e-03   7.39436441e-05  -1.25914729e-02   1.05320012e-02\n",
      "   -1.34641420e-03   6.99092246e-03   1.41283790e-03   1.19854028e-02\n",
      "    1.75817156e-02   4.28777153e-03   5.54703152e-03  -1.42629195e-03\n",
      "    1.20903328e-04   1.19237806e-03   3.34065322e-03  -4.65388719e-03\n",
      "   -6.89759483e-03  -9.52234454e-03   5.80749131e-03   4.29274870e-03\n",
      "   -4.28831390e-03   4.36484589e-03   6.26847661e-03  -7.91304951e-03\n",
      "   -6.66092621e-03   3.39185785e-03   5.23093644e-03  -1.23205866e-02\n",
      "   -9.14520338e-03  -3.70505174e-03  -4.71375087e-03   1.37359606e-04\n",
      "    2.38594249e-03  -2.25520045e-03   4.81146547e-03  -2.35209257e-03\n",
      "    6.19867364e-04   5.62475781e-03  -1.61205596e-03   9.30042071e-03\n",
      "   -4.91606090e-03   3.39154627e-03  -2.54190026e-03   1.06651034e-03\n",
      "    6.87292967e-03   1.28502055e-02   2.52497010e-04  -9.44680382e-03]]\n",
      "Y_validation : [ 1.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2016)\n",
    "n_examples = A.shape[0]\n",
    "print(\"A.shape[0]:\", n_examples)\n",
    "n_train = int(n_examples * 0.6)\n",
    "train_idx = list(np.random.choice(n_examples, size=n_train, replace=False)) #changed array to list\n",
    "n_validation = int(n_examples*0.2)\n",
    "validation_set = list(set(range(0,n_examples))-set(train_idx))\n",
    "validation_idx = list(np.random.choice(validation_set, size=n_validation, replace=False)) #hold-out values for validation\n",
    "test_idx = list(set(range(0,n_examples))- set(train_idx) - set(validation_idx))\n",
    "A_train=np.zeros((96000,2,128),np.float64)\n",
    "Y_train=np.zeros((96000,4),np.float64)\n",
    "A_test=np.zeros((32000,2,128),np.float64)\n",
    "Y_test=np.zeros((32000,4),np.float64)\n",
    "A_validation=np.zeros((32000,2,128),np.float64)\n",
    "Y_validation=np.zeros((32000,4),np.float64)\n",
    "\n",
    "#More Shuffling in place\n",
    "np.random.shuffle(train_idx)\n",
    "np.random.shuffle(test_idx)\n",
    "np.random.shuffle(validation_idx)\n",
    "\n",
    "#Filling in A and Y tensors\n",
    "z=0\n",
    "for p in train_idx:\n",
    "    A_train[z] = A[p]\n",
    "    Y_train[z] = lbl[p]\n",
    "    z=z+1\n",
    "\n",
    "z=0\n",
    "for q in test_idx:\n",
    "    A_test[z] = A[q]\n",
    "    Y_test[z] = lbl[q]\n",
    "    z=z+1\n",
    "\n",
    "z=0\n",
    "for r in validation_idx:\n",
    "    A_validation[z] = A[r]\n",
    "    Y_validation[z] = lbl[r]\n",
    "    z=z+1\n",
    "\n",
    "#For verification, A[last_validation] = A_validation[-1] and lbl[last_validation] = Y_validation[-1] \n",
    "last_validation=validation_idx[-1]\n",
    "print(\"A_validation :\", A[last_validation])\n",
    "print(\"Y_validation :\", lbl[last_validation])\n",
    "print(\"A_validation :\",A_validation[-1])\n",
    "print(\"Y_validation :\", Y_validation[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training in Keras Model\n",
    "Prints out Input Shape of Dataset and set up 2-layered CNN Model with Default Adam Optimizer Values, Dropout Rate = 50%, Number of Epochs = 500, Batch Size=1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A_train.shape, Y_train.shape, in_shp : (96000, 2, 128) (96000, 4) [2, 128]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_3 (Reshape)          (None, 1, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPaddin (None, 1, 2, 132)         0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 256, 2, 130)       1024      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256, 2, 130)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPaddin (None, 256, 2, 134)       0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 80, 1, 132)        122960    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 80, 1, 132)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 10560)             0         \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 256)               2703616   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense2 (Dense)               (None, 4)                 1028      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,828,628\n",
      "Trainable params: 2,828,628\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model set up\n",
      "Training NN\n"
     ]
    }
   ],
   "source": [
    "in_shp = list(A_train.shape[1:])\n",
    "print (\"A_train.shape, Y_train.shape, in_shp :\", A_train.shape,Y_train.shape,in_shp)\n",
    "classes=n #Classes to be predicted, i.e. the Modulation Types\n",
    "#Set up some params\n",
    "adam = adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8, decay=0)\n",
    "dr = 0.5 # dropout rate (%)\n",
    "epochs=500\n",
    "batch_size= 1024\n",
    "model = models.Sequential()\n",
    "model.add(Reshape((1,2,128),input_shape=in_shp))\n",
    "model.add(ZeroPadding2D((0, 2), data_format='channels_first'))\n",
    "model.add(Convolution2D(256,(1,3), activation=\"relu\", name=\"conv1\", padding=\"valid\", kernel_initializer='glorot_uniform',data_format='channels_first'))\n",
    "model.add(Dropout(dr))\n",
    "model.add(ZeroPadding2D((0, 2), data_format='channels_first'))\n",
    "model.add(Convolution2D(80,(2, 3), activation=\"relu\", name=\"conv2\", padding=\"valid\", kernel_initializer='glorot_uniform',data_format='channels_first'))\n",
    "model.add(Dropout(dr))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu', kernel_initializer='he_normal', name=\"dense1\"))\n",
    "model.add(Dropout(dr))\n",
    "model.add(Dense( len(classes), kernel_initializer='he_normal', name=\"dense2\" ))\n",
    "model.add(Activation('softmax'))\n",
    "model.add(Reshape([len(classes)]))\n",
    "#compile/configure models\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"]) \n",
    "model.summary()\n",
    "#t1=time.time()\n",
    "#lapsed_time=t1-t0\n",
    "#print(\"Lapsed time is %0.2f seconds\" %lapsed_time)\n",
    "print(\"Model set up\")\n",
    "print(\"Training NN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that NN is initialized with random weights and shape of weights are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimension 1 in both shapes must be equal, but are 4 and 11 for 'Assign_6' (op: 'Assign') with input shapes: [256,4], [256,11].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    685\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[1;32m    687\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimension 1 in both shapes must be equal, but are 4 and 11 for 'Assign_6' (op: 'Assign') with input shapes: [256,4], [256,11].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-994b04693921>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'WeightsfromRadioMLDataset.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading weights from trained NN1 with RadioML Dataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0mtopology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m             \u001b[0mtopology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'close'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m   3093\u001b[0m                              ' elements.')\n\u001b[1;32m   3094\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3095\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   2186\u001b[0m                 assign_placeholder = tf.placeholder(tf_dtype,\n\u001b[1;32m   2187\u001b[0m                                                     shape=value.shape)\n\u001b[0;32m-> 2188\u001b[0;31m                 \u001b[0massign_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2189\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_placeholder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_placeholder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2190\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, value, use_locking)\u001b[0m\n\u001b[1;32m    571\u001b[0m       \u001b[0mthe\u001b[0m \u001b[0massignment\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mcompleted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m     \"\"\"\n\u001b[0;32m--> 573\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mstate_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0massign_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/ops/state_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[1;32m    274\u001b[0m     return gen_state_ops.assign(\n\u001b[1;32m    275\u001b[0m         \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         validate_shape=validate_shape)\n\u001b[0m\u001b[1;32m    277\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/ops/gen_state_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[1;32m     55\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m     56\u001b[0m         \u001b[0;34m\"Assign\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         use_locking=use_locking, name=name)\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2956\u001b[0m         op_def=op_def)\n\u001b[1;32m   2957\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2958\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2959\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2960\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2207\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2209\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2210\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2211\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2159\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2161\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, require_shape_fn)\u001b[0m\n\u001b[1;32m    625\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    626\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m                                   require_shape_fn)\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    689\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimension 1 in both shapes must be equal, but are 4 and 11 for 'Assign_6' (op: 'Assign') with input shapes: [256,4], [256,11]."
     ]
    }
   ],
   "source": [
    "filepath='WeightsfromRadioMLDataset.h5'\n",
    "model.load_weights(filepath)\n",
    "print(\"Loading weights from trained NN1 with RadioML Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start training and record total training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 96000 samples, validate on 32000 samples\n",
      "Epoch 1/500\n",
      "20s - loss: 1.3264 - acc: 0.3727 - val_loss: 1.3233 - val_acc: 0.3763\n",
      "Epoch 2/500\n",
      "19s - loss: 1.3227 - acc: 0.3734 - val_loss: 1.3310 - val_acc: 0.3763\n",
      "Epoch 3/500\n",
      "19s - loss: 1.3202 - acc: 0.3734 - val_loss: 1.3142 - val_acc: 0.3763\n",
      "Epoch 4/500\n",
      "19s - loss: 1.3164 - acc: 0.3737 - val_loss: 1.3136 - val_acc: 0.3763\n",
      "Epoch 5/500\n",
      "19s - loss: 1.3112 - acc: 0.3752 - val_loss: 1.3039 - val_acc: 0.3782\n",
      "Epoch 6/500\n",
      "19s - loss: 1.3048 - acc: 0.3805 - val_loss: 1.2967 - val_acc: 0.3827\n",
      "Epoch 7/500\n",
      "20s - loss: 1.2962 - acc: 0.3850 - val_loss: 1.2889 - val_acc: 0.3855\n",
      "Epoch 8/500\n",
      "19s - loss: 1.2891 - acc: 0.3894 - val_loss: 1.2810 - val_acc: 0.3943\n",
      "Epoch 9/500\n",
      "19s - loss: 1.2786 - acc: 0.3951 - val_loss: 1.2680 - val_acc: 0.4001\n",
      "Epoch 10/500\n",
      "19s - loss: 1.2663 - acc: 0.4043 - val_loss: 1.2558 - val_acc: 0.4224\n",
      "Epoch 11/500\n",
      "19s - loss: 1.2420 - acc: 0.4244 - val_loss: 1.2226 - val_acc: 0.4361\n",
      "Epoch 12/500\n",
      "19s - loss: 1.2053 - acc: 0.4452 - val_loss: 1.1758 - val_acc: 0.4631\n",
      "Epoch 13/500\n",
      "19s - loss: 1.1753 - acc: 0.4647 - val_loss: 1.1312 - val_acc: 0.4993\n",
      "Epoch 14/500\n",
      "19s - loss: 1.1543 - acc: 0.4800 - val_loss: 1.1114 - val_acc: 0.5068\n",
      "Epoch 15/500\n",
      "19s - loss: 1.1298 - acc: 0.4952 - val_loss: 1.0915 - val_acc: 0.5315\n",
      "Epoch 16/500\n",
      "19s - loss: 1.1098 - acc: 0.5070 - val_loss: 1.0770 - val_acc: 0.5411\n",
      "Epoch 17/500\n",
      "19s - loss: 1.0904 - acc: 0.5200 - val_loss: 1.0517 - val_acc: 0.5494\n",
      "Epoch 18/500\n",
      "19s - loss: 1.0745 - acc: 0.5286 - val_loss: 1.0333 - val_acc: 0.5621\n",
      "Epoch 19/500\n",
      "19s - loss: 1.0552 - acc: 0.5389 - val_loss: 1.0169 - val_acc: 0.5727\n",
      "Epoch 20/500\n",
      "19s - loss: 1.0373 - acc: 0.5494 - val_loss: 1.0060 - val_acc: 0.5732\n",
      "Epoch 21/500\n",
      "19s - loss: 1.0213 - acc: 0.5574 - val_loss: 0.9838 - val_acc: 0.5859\n",
      "Epoch 22/500\n",
      "19s - loss: 1.0074 - acc: 0.5656 - val_loss: 0.9701 - val_acc: 0.5929\n",
      "Epoch 23/500\n",
      "19s - loss: 0.9915 - acc: 0.5736 - val_loss: 0.9515 - val_acc: 0.6037\n",
      "Epoch 24/500\n",
      "19s - loss: 0.9736 - acc: 0.5811 - val_loss: 0.9453 - val_acc: 0.6009\n",
      "Epoch 25/500\n",
      "19s - loss: 0.9632 - acc: 0.5868 - val_loss: 0.9330 - val_acc: 0.6074\n",
      "Epoch 26/500\n",
      "19s - loss: 0.9513 - acc: 0.5932 - val_loss: 0.9405 - val_acc: 0.6034\n",
      "Epoch 27/500\n",
      "19s - loss: 0.9375 - acc: 0.5994 - val_loss: 0.9133 - val_acc: 0.6218\n",
      "Epoch 28/500\n",
      "19s - loss: 0.9184 - acc: 0.6092 - val_loss: 0.8980 - val_acc: 0.6244\n",
      "Epoch 29/500\n",
      "19s - loss: 0.9104 - acc: 0.6108 - val_loss: 0.8972 - val_acc: 0.6234\n",
      "Epoch 30/500\n",
      "19s - loss: 0.8956 - acc: 0.6209 - val_loss: 0.8889 - val_acc: 0.6216\n",
      "Epoch 31/500\n",
      "20s - loss: 0.8895 - acc: 0.6207 - val_loss: 0.8797 - val_acc: 0.6293\n",
      "Epoch 32/500\n",
      "19s - loss: 0.8817 - acc: 0.6256 - val_loss: 0.8758 - val_acc: 0.6265\n",
      "Epoch 33/500\n",
      "19s - loss: 0.8694 - acc: 0.6330 - val_loss: 0.8623 - val_acc: 0.6388\n",
      "Epoch 34/500\n",
      "19s - loss: 0.8599 - acc: 0.6363 - val_loss: 0.8543 - val_acc: 0.6414\n",
      "Epoch 35/500\n",
      "19s - loss: 0.8515 - acc: 0.6419 - val_loss: 0.8468 - val_acc: 0.6456\n",
      "Epoch 36/500\n",
      "19s - loss: 0.8430 - acc: 0.6429 - val_loss: 0.8431 - val_acc: 0.6483\n",
      "Epoch 37/500\n",
      "19s - loss: 0.8312 - acc: 0.6510 - val_loss: 0.8355 - val_acc: 0.6500\n",
      "Epoch 38/500\n",
      "19s - loss: 0.8240 - acc: 0.6539 - val_loss: 0.8415 - val_acc: 0.6470\n",
      "Epoch 39/500\n",
      "19s - loss: 0.8146 - acc: 0.6588 - val_loss: 0.8310 - val_acc: 0.6498\n",
      "Epoch 40/500\n",
      "19s - loss: 0.8067 - acc: 0.6602 - val_loss: 0.8212 - val_acc: 0.6552\n",
      "Epoch 41/500\n",
      "19s - loss: 0.8031 - acc: 0.6636 - val_loss: 0.8215 - val_acc: 0.6539\n",
      "Epoch 42/500\n",
      "19s - loss: 0.7871 - acc: 0.6702 - val_loss: 0.8157 - val_acc: 0.6585\n",
      "Epoch 43/500\n",
      "19s - loss: 0.7848 - acc: 0.6727 - val_loss: 0.8111 - val_acc: 0.6589\n",
      "Epoch 44/500\n",
      "19s - loss: 0.7816 - acc: 0.6717 - val_loss: 0.8071 - val_acc: 0.6642\n",
      "Epoch 45/500\n",
      "19s - loss: 0.7647 - acc: 0.6811 - val_loss: 0.8054 - val_acc: 0.6623\n",
      "Epoch 46/500\n",
      "19s - loss: 0.7643 - acc: 0.6810 - val_loss: 0.8031 - val_acc: 0.6594\n",
      "Epoch 47/500\n",
      "19s - loss: 0.7565 - acc: 0.6851 - val_loss: 0.7950 - val_acc: 0.6668\n",
      "Epoch 48/500\n",
      "19s - loss: 0.7496 - acc: 0.6886 - val_loss: 0.7902 - val_acc: 0.6698\n",
      "Epoch 49/500\n",
      "19s - loss: 0.7397 - acc: 0.6924 - val_loss: 0.7870 - val_acc: 0.6704\n",
      "Epoch 50/500\n",
      "19s - loss: 0.7391 - acc: 0.6921 - val_loss: 0.7904 - val_acc: 0.6679\n",
      "Epoch 51/500\n",
      "19s - loss: 0.7280 - acc: 0.6976 - val_loss: 0.7884 - val_acc: 0.6663\n",
      "Epoch 52/500\n",
      "19s - loss: 0.7201 - acc: 0.7007 - val_loss: 0.7778 - val_acc: 0.6741\n",
      "Epoch 53/500\n",
      "19s - loss: 0.7192 - acc: 0.6992 - val_loss: 0.7768 - val_acc: 0.6744\n",
      "Epoch 54/500\n",
      "19s - loss: 0.7104 - acc: 0.7056 - val_loss: 0.7744 - val_acc: 0.6752\n",
      "Epoch 55/500\n",
      "19s - loss: 0.7038 - acc: 0.7084 - val_loss: 0.7839 - val_acc: 0.6715\n",
      "Epoch 56/500\n",
      "19s - loss: 0.6959 - acc: 0.7106 - val_loss: 0.7701 - val_acc: 0.6776\n",
      "Epoch 57/500\n",
      "19s - loss: 0.6900 - acc: 0.7145 - val_loss: 0.7793 - val_acc: 0.6682\n",
      "Epoch 58/500\n",
      "19s - loss: 0.6872 - acc: 0.7168 - val_loss: 0.7700 - val_acc: 0.6736\n",
      "Epoch 59/500\n",
      "19s - loss: 0.6862 - acc: 0.7165 - val_loss: 0.7630 - val_acc: 0.6798\n",
      "Epoch 60/500\n",
      "19s - loss: 0.6754 - acc: 0.7196 - val_loss: 0.7682 - val_acc: 0.6790\n",
      "Epoch 61/500\n",
      "19s - loss: 0.6750 - acc: 0.7221 - val_loss: 0.7616 - val_acc: 0.6819\n",
      "Epoch 62/500\n",
      "19s - loss: 0.6701 - acc: 0.7239 - val_loss: 0.7544 - val_acc: 0.6837\n",
      "Epoch 63/500\n",
      "19s - loss: 0.6648 - acc: 0.7254 - val_loss: 0.7533 - val_acc: 0.6833\n",
      "Epoch 64/500\n",
      "20s - loss: 0.6534 - acc: 0.7322 - val_loss: 0.7578 - val_acc: 0.6835\n",
      "Epoch 65/500\n",
      "19s - loss: 0.6541 - acc: 0.7332 - val_loss: 0.7504 - val_acc: 0.6847\n",
      "Epoch 66/500\n",
      "19s - loss: 0.6454 - acc: 0.7335 - val_loss: 0.7513 - val_acc: 0.6842\n",
      "Epoch 67/500\n",
      "19s - loss: 0.6444 - acc: 0.7359 - val_loss: 0.7512 - val_acc: 0.6857\n",
      "Epoch 68/500\n",
      "20s - loss: 0.6389 - acc: 0.7379 - val_loss: 0.7450 - val_acc: 0.6864\n",
      "Epoch 69/500\n",
      "19s - loss: 0.6358 - acc: 0.7389 - val_loss: 0.7486 - val_acc: 0.6867\n",
      "Epoch 70/500\n",
      "19s - loss: 0.6318 - acc: 0.7413 - val_loss: 0.7435 - val_acc: 0.6880\n",
      "Epoch 71/500\n",
      "19s - loss: 0.6252 - acc: 0.7450 - val_loss: 0.7421 - val_acc: 0.6882\n",
      "Epoch 72/500\n",
      "19s - loss: 0.6262 - acc: 0.7416 - val_loss: 0.7410 - val_acc: 0.6894\n",
      "Epoch 73/500\n",
      "19s - loss: 0.6184 - acc: 0.7468 - val_loss: 0.7427 - val_acc: 0.6907\n",
      "Epoch 74/500\n",
      "19s - loss: 0.6173 - acc: 0.7464 - val_loss: 0.7536 - val_acc: 0.6837\n",
      "Epoch 75/500\n",
      "19s - loss: 0.6133 - acc: 0.7491 - val_loss: 0.7411 - val_acc: 0.6907\n",
      "Epoch 76/500\n",
      "19s - loss: 0.6092 - acc: 0.7499 - val_loss: 0.7408 - val_acc: 0.6883\n",
      "Epoch 77/500\n",
      "19s - loss: 0.6041 - acc: 0.7534 - val_loss: 0.7345 - val_acc: 0.6908\n",
      "Epoch 78/500\n",
      "19s - loss: 0.6031 - acc: 0.7535 - val_loss: 0.7369 - val_acc: 0.6903\n",
      "Epoch 79/500\n",
      "19s - loss: 0.5973 - acc: 0.7564 - val_loss: 0.7380 - val_acc: 0.6905\n",
      "Epoch 80/500\n",
      "19s - loss: 0.5973 - acc: 0.7563 - val_loss: 0.7341 - val_acc: 0.6935\n",
      "Epoch 81/500\n",
      "19s - loss: 0.5904 - acc: 0.7581 - val_loss: 0.7309 - val_acc: 0.6932\n",
      "Epoch 82/500\n",
      "19s - loss: 0.5891 - acc: 0.7593 - val_loss: 0.7447 - val_acc: 0.6866\n",
      "Epoch 83/500\n",
      "19s - loss: 0.5851 - acc: 0.7612 - val_loss: 0.7407 - val_acc: 0.6869\n",
      "Epoch 84/500\n",
      "19s - loss: 0.5808 - acc: 0.7644 - val_loss: 0.7355 - val_acc: 0.6926\n",
      "Epoch 85/500\n",
      "19s - loss: 0.5817 - acc: 0.7608 - val_loss: 0.7364 - val_acc: 0.6936\n",
      "Epoch 86/500\n",
      "19s - loss: 0.5813 - acc: 0.7644 - val_loss: 0.7382 - val_acc: 0.6893\n",
      "Epoch 87/500\n",
      "19s - loss: 0.5725 - acc: 0.7669 - val_loss: 0.7311 - val_acc: 0.6920\n",
      "Total Training Time for NN1:  996.9924629999999  seconds\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(A_train,Y_train,batch_size=batch_size,epochs=epochs,verbose=2,validation_data=(A_validation, Y_validation),callbacks =[keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True, mode='auto'),keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print scores [Loss, Accuracy] and plot training accuracy and loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73113847827911382, 0.69199999999999995]\n"
     ]
    }
   ],
   "source": [
    "score=model.evaluate(A_validation, Y_validation, verbose=0, batch_size=batch_size)\n",
    "print(score)\n",
    "#plot accuracy curves\n",
    "plt.figure(1)\n",
    "plt.subplot(211)\n",
    "plt.title('Accuracy plot')\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train','validation'], loc='upper left')\n",
    "\n",
    "#plot loss curves\n",
    "plt.subplot(212)\n",
    "plt.title('Training performance')\n",
    "plt.plot(history.epoch, history.history['loss'], label='train loss+error')\n",
    "plt.plot(history.epoch,history.history['val_loss'],label='val_error')\n",
    "plt.ylabel('Error')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train','validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting with Trained Weights\n",
    "Load weights, start prediction, plot confusion matrix for all SNRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded weights from Disk\n",
      "31744/32000 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "model.load_weights(filepath)\n",
    "print(\"Loaded weights from Disk\")\n",
    "\n",
    "#defines function which return all indices for value\n",
    "def all_indices(value, qlist):\n",
    "    indices = []\n",
    "    idx = -1\n",
    "    while True:\n",
    "        try:\n",
    "            idx = qlist.index(value, idx+1)\n",
    "            indices.append(idx)\n",
    "        except ValueError:\n",
    "            break\n",
    "    return indices\n",
    "\n",
    "#defines function to plot confusion matrix\n",
    "def plot_confusion_matrix(cm, title, cmap=plt.cm.Blues, labels=[]):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(labels))\n",
    "    plt.xticks(tick_marks, labels, rotation=45)\n",
    "    plt.yticks(tick_marks, labels)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    #plt.show\n",
    "    plt.savefig(title,format='png')\n",
    "\n",
    "#Given A_test, predict Y_hat\n",
    "test_Y_hat = model.predict(A_test, batch_size=batch_size, verbose=1)\n",
    "#Initialise zero vectors for confusion matrix ( normalized and before normalization)\n",
    "conf = np.zeros([len(classes),len(classes)])\n",
    "confnorm = np.zeros([len(classes),len(classes)])\n",
    "for m in range(0,A_test.shape[0]):\n",
    "    n = list(Y_test[m,:]).index(1)\n",
    "    o = int(np.argmax(test_Y_hat[m,:]))\n",
    "    conf[n,o] = conf[n,o] + 1\n",
    "for i in range(0,len(classes)):\n",
    "    confnorm[i,:] = conf[i,:] / np.sum(conf[i,:])\n",
    "\n",
    "#Plot the first confusion matrix for all SNRs\n",
    "plot_confusion_matrix(confnorm,title=\"Confusion_Matrix_for_all_SNRs\",labels=classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict and plot Confusion Matrix according to SNRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/louisa/anaconda3/lib/python3.5/site-packages/matplotlib/pyplot.py:524: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy:  0.694670846395\n",
      "Overall Accuracy:  0.774412855377\n",
      "Overall Accuracy:  0.668918918919\n",
      "Overall Accuracy:  0.683076923077\n",
      "Overall Accuracy:  0.653775322284\n",
      "Overall Accuracy:  0.721706864564\n",
      "Overall Accuracy:  0.57087628866\n",
      "Overall Accuracy:  0.658491722869\n",
      "Overall Accuracy:  0.71835443038\n",
      "Overall Accuracy:  0.656015037594\n",
      "Overall Accuracy:  0.684345047923\n",
      "Overall Accuracy:  0.787411689146\n",
      "Overall Accuracy:  0.686261980831\n",
      "Overall Accuracy:  0.630692451653\n",
      "Overall Accuracy:  0.757748260595\n",
      "Overall Accuracy:  0.688649334179\n",
      "Overall Accuracy:  0.744112030554\n",
      "Overall Accuracy:  0.657734470158\n",
      "Overall Accuracy:  0.69302615193\n",
      "Overall Accuracy:  0.723225030084\n",
      "{0: 0.69467084639498433, 1: 0.77441285537700866, 2: 0.66891891891891897, 3: 0.68307692307692303, 4: 0.65377532228360957, 5: 0.72170686456400746, 6: 0.57087628865979378, 7: 0.65849172286940527, 8: 0.71835443037974689, 9: 0.65601503759398494, 10: 0.68434504792332274, 11: 0.78741168914579318, 12: 0.68626198083067091, 13: 0.63069245165315035, 14: 0.75774826059456035, 15: 0.68864933417882057, 16: 0.74411203055378738, 17: 0.65773447015834352, 18: 0.69302615193026151, 19: 0.72322503008423589}\n",
      "a [0.69467084639498433, 0.77441285537700866, 0.66891891891891897, 0.68307692307692303, 0.65377532228360957, 0.72170686456400746, 0.57087628865979378, 0.65849172286940527, 0.71835443037974689, 0.65601503759398494, 0.68434504792332274, 0.78741168914579318, 0.68626198083067091, 0.63069245165315035, 0.75774826059456035, 0.68864933417882057, 0.74411203055378738, 0.65773447015834352, 0.69302615193026151, 0.72322503008423589]\n"
     ]
    }
   ],
   "source": [
    "#Initialise acc and test_SNRs\n",
    "acc = {}\n",
    "test_SNRs=[]\n",
    "\n",
    "#Generate a list of test_SNRs\n",
    "for i in test_idx:\n",
    "    test_SNRs.append(snr[i])\n",
    "\n",
    "#Extract sigvalues and labels @ SNR\n",
    "for snr in k:\n",
    "    test_X_i = A_test[all_indices([snr],test_SNRs)]\n",
    "    test_Y_i = Y_test[all_indices([snr],test_SNRs)]\n",
    "    test_Y_i_hat = model.predict(test_X_i)\n",
    "    conf = np.zeros([len(classes),len(classes)])\n",
    "    confnorm = np.zeros([len(classes),len(classes)])\n",
    "    for j in range(0,test_X_i.shape[0]):\n",
    "        true = list(test_Y_i[j,:]).index([1])\n",
    "        predicted = int(np.argmax(test_Y_i_hat[j,:]))\n",
    "        conf[true,predicted] = conf[true,predicted] + 1\n",
    "    #np.seterr(divide='ignore',invalid='ignore')\n",
    "    for ct in range(0,len(classes)):\n",
    "        confnorm[ct,:] = conf[ct,:] / np.sum(conf[ct,:])\n",
    "    #print(\"conf\",conf)\n",
    "    #print(\"confnorm\",confnorm)\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(confnorm, labels=classes, title=\"ConvNet Confusion Matrix (SNR=%d)\"%(snr))\n",
    "    \n",
    "    cor = np.sum(np.diag(conf))\n",
    "    ncor = np.sum(conf) - cor\n",
    "    print (\"Overall Accuracy: \", cor / (cor+ncor))\n",
    "    acc[snr] = 1.0*cor/(cor+ncor)\n",
    "# Save results to a pickle file for plotting later\n",
    "print (acc)\n",
    "a=list(map(lambda x:acc[x], k))\n",
    "print(\"a\",a)\n",
    "with open('results_cnn2_d0.5.dat','wb') as fd:\n",
    "    cPickle.dump((\"CNN2_080218\", 0.5, acc),fd)\n",
    "# Plot accuracy curve\n",
    "fig=plt.figure()\n",
    "plt.plot(k, a)\n",
    "plt.xlabel(\"Signal to Noise Ratio\")\n",
    "plt.ylabel(\"Classification Accuracy\")\n",
    "plt.title(\"CNN2 Classification Accuracy on Dataset 7.146\")\n",
    "plt.show()\n",
    "fig.savefig('Accplot.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
